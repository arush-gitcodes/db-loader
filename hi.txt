~##~12000.00~##~4.25~##~2023-04-01~##~2026-04-01
>>USING PANDAS
def insert_data(self):
    # Extract files from the ZIP archive
    self.extract_files(self.zip_file_path, extract_to='extracted_data')

    inserted_tables = 0
    try:
        with self.connect_to_db() as conn:
            with conn.cursor() as cursor:
                for table_name, columns in self.table_column_mapping.items():
                    target_columns = columns['target_columns']
                    source_columns = columns['source_columns']
                    data_file_name = columns['data_file']

                    if not self.table_exists(cursor, table_name):
                        logging.warning(f"Table {self.db_schema}.{table_name} does not exist.")
                        continue

                    dat_file_path = os.path.join('extracted_data', f'{data_file_name}.dat')
                    if not os.path.isfile(dat_file_path):
                        logging.warning(f"File for table {table_name} ({data_file_name}.dat) does not exist in the ZIP archive.")
                        continue

                    start_time = datetime.now()
                    logging.info(f"Starting data ingestion for table {self.db_schema}.{table_name} at {start_time}")

                    # >>>Read the data file into a pandas DataFrame
                    df = pd.read_csv(dat_file_path, delimiter=self.column_delimiter, encoding=self.encoding, header=None, skiprows=self.skip_header_rows)

                    # Skip footer rows
                    if self.skip_footer_rows > 0:
                        df = df[:-self.skip_footer_rows]

                    # Rename columns based on the mapping
                    df.columns = source_columns

                    # Select only the columns needed for the target table
                    df = df[target_columns]

                    # Ensure interest_rate is at least 3
                    if 'interest_rate' in df.columns:
                        df['interest_rate'] = df['interest_rate'].apply(lambda x: max(3, float(x)))

                    # Convert DataFrame to list of tuples for batch insertion
                    data_tuples = [tuple(x) for x in df.to_numpy()]

                    for i in range(0, len(data_tuples), self.batch_size):
                        batch = data_tuples[i:i + self.batch_size]
                        insert_query = (
                            f"INSERT INTO {self.db_schema}.{table_name} ({', '.join(target_columns)}) "
                            f"VALUES %s"
                        )
                        psycopg2.extras.execute_values(cursor, insert_query, batch)

                    end_time = datetime.now()
                    logging.info(f"Completed data ingestion for table {self.db_schema}.{table_name} at {end_time}")
                    logging.info(f"Duration: {end_time - start_time}")

                    inserted_tables += 1

            conn.commit()
            logging.info(f"Data inserted successfully into {inserted_tables} tables.")
    except psycopg2.Error as db_error:
        logging.error(f"Database error: {db_error}")
    except Exception as e:
        logging.error(f"Error: {e}")


>> Normal approach
if 'interest_rate' in target_columns:
                   interest_rate_index = target_columns.index('interest_rate')
                   selected_values[interest_rate_index] = max(3, float(selected_values[interest_rate_index]))
if 'account_id' in target_columns:
                   account_id_index = target_columns.index('account_id')
                   selected_values[account_id_index] = selected_values[account_id_index][-2:]

>dynamic
def transform_interest_rate(value):
    return max(3, float(value))

def transform_account_id(value):
    return value[-2:]

column_transformations = {
    'interest_rate': transform_interest_rate,
    'account_id': transform_account_id,
    # Add more column transformations as needed
    'example_column': transform_column_example
}
for col in target_columns:
                            if col in column_transformations:
                                idx = target_columns.index(col)
                                selected_values[idx] = column_transformations[col](selected_values[idx])
